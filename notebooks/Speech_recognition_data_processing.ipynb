{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "from glob import glob as glob_module\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "import logging\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, filename=\"log.log\", filemode=\"w\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "handler = logging.FileHandler(\"dataprocessing_test.log\", mode=\"w\")\n",
    "formatter = logging.Formatter(\"%(name)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(curr_notebook_dir,os.pardir))\n",
    "train_path = r\"data\\raw\\LibriSpeech\\train-clean-100\\LibriSpeech\\train-clean-100\\**\\**\\*.flac\"\n",
    "test_path = r\"data\\raw\\LibriSpeech\\test-clean\\LibriSpeech\\test-clean\\**\\**\\*.flac\"\n",
    "dev_path = r\"data\\raw\\LibriSpeech\\dev-clean\\LibriSpeech\\dev-clean\\**\\**\\*.flac\"\n",
    "\n",
    "train_path_whole = os.path.join(parent_dir,train_path)\n",
    "test_path_whole = os.path.join(parent_dir,test_path)\n",
    "dev_path_whole = os.path.join(parent_dir,dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_train = glob_module(train_path_whole, recursive=True)\n",
    "data_files_dev = glob_module(dev_path_whole, recursive=True)\n",
    "data_files_test = glob_module(test_path_whole, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_data, sample_rate = sf.read(data_files_dev[849])\n",
    "# sd.play(audio_data,samplerate=sample_rate)\n",
    "# sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# Pxx, freqs, bins, im = plt.specgram(audio_data, NFFT=256, Fs=sample_rate, noverlap=128, cmap=\"jet\")\n",
    "\n",
    "# plt.colorbar(label='Intensity [dB]')\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.xlabel('Time [s]')\n",
    "# plt.title('Spectrogram')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfccs = mfcc(audio_data, sample_rate, numcep=13)\n",
    "# mfccs_l = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
    "# mfccs_normalized = (mfccs - np.mean(mfccs, axis=0)) / np.std(mfccs, axis=0)\n",
    "# mfccs_l_normalized = (mfccs_l - np.mean(mfccs_l, axis=0)) / np.std(mfccs_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(mfccs_normalized, cmap=\"jet\", origin='lower', aspect='auto')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCCs')\n",
    "# plt.ylabel('Time')\n",
    "# plt.xlabel('MFCC Coefficients')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(file_path):\n",
    "    try:\n",
    "        audio_data, sample_rate = sf.read(file_path)\n",
    "        logger.info(\"Audio data loaded successfully.\")\n",
    "        \n",
    "        Pxx, freqs, bins, im = plt.specgram(audio_data, NFFT=256, Fs=sample_rate, noverlap=128, cmap=\"jet\")\n",
    "        logger.info(\"Spectrogram computed successfully.\")\n",
    "        \n",
    "        mfccs = mfcc(audio_data, samplerate=sample_rate, numcep=13)\n",
    "        logger.info(\"MFCCs computed successfully.\")\n",
    "        \n",
    "        mfccs_normalized = (mfccs - np.mean(mfccs, axis=0)) / np.std(mfccs, axis=0)\n",
    "        logger.info(\"MFCCs normalized successfully.\")\n",
    "        \n",
    "        return Pxx, mfccs_normalized\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing audio file: {file_path}. Error message: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = Parallel(n_jobs=8)(delayed(process_audio)(file_path) for file_path in data_files_train)\n",
    "audio_feature_list_train, mfcc_list_train = zip(*[result for result in results_train if result[0] is not None and result[1] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = Parallel(n_jobs=8)(delayed(process_audio)(file_path) for file_path in data_files_test)\n",
    "audio_feature_list_test, mfcc_list_test = zip(*[result for result in results_test if result[0] is not None and result[1] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dev = Parallel(n_jobs=8)(delayed(process_audio)(file_path) for file_path in data_files_dev)\n",
    "audio_feature_list_dev, mfcc_list_dev = zip(*[result for result in results_dev if result[0] is not None and result[1] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_feature_list_train,mfcc_list_train = [], []\n",
    "# for i, file_path in enumerate(data_files_train):\n",
    "#     audio_feature, mfcc_feature = process_audio(file_path)\n",
    "#     if audio_feature is not None and mfcc_feature is not None:\n",
    "#         audio_feature_list_train.append(audio_feature)\n",
    "#         mfcc_list_train.append(mfcc_feature)\n",
    "#     else:\n",
    "#         logging.error(f\"Error processing audio file at index {i}: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_feature_list_test,mfcc_list_test = [], []\n",
    "# for i, file_path in enumerate(data_files_test):\n",
    "#     audio_feature, mfcc_feature = process_audio(file_path)\n",
    "#     if audio_feature is not None and mfcc_feature is not None:\n",
    "#         audio_feature_list_test.append(audio_feature)\n",
    "#         mfcc_list_test.append(mfcc_feature)\n",
    "#     else:\n",
    "#         logger.error(f\"Error processing audio file at index {i}: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_feature_list_dev,mfcc_list_dev = [], []\n",
    "# for i, file_path in enumerate(data_files_dev):\n",
    "#     audio_feature, mfcc_feature = process_audio(file_path)\n",
    "#     if audio_feature is not None and mfcc_feature is not None:\n",
    "#         audio_feature_list_dev.append(audio_feature)\n",
    "#         mfcc_list_dev.append(mfcc_feature)\n",
    "#     else:\n",
    "#         logging.error(f\"Error processing audio file at index {i}: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(file):\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name_abs = file_name.split(\".\")\n",
    "    cur_dir = os.path.dirname(file)\n",
    "    transcript_file = glob_module(os.path.join(cur_dir, \"*.txt\"))\n",
    "    with open(transcript_file[0],\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    first_words_list = [(line.split()[0],i) for i,line in enumerate(lines)]\n",
    "    for elements in first_words_list:\n",
    "        if elements[0]==file_name_abs[0]:\n",
    "            line = lines[elements[1]]\n",
    "            line = line.split()\n",
    "            transcript = \" \".join(line[1:])\n",
    "            break\n",
    "    return {file_name_abs[0]:transcript}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_transcripts_train = []\n",
    "for file in data_files_train:\n",
    "    transcript = corpus(file)\n",
    "    ordered_transcripts_train.append(transcript)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_transcripts_test = []\n",
    "for file in data_files_test:\n",
    "    transcript = corpus(file)\n",
    "    ordered_transcripts_test.append(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_transcripts_dev = []\n",
    "for file in data_files_dev:\n",
    "    transcript = corpus(file)\n",
    "    ordered_transcripts_dev.append(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = r\"data\\processed\"\n",
    "curr_notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(curr_notebook_dir,os.pardir))\n",
    "corpus_path_whole = os.path.join(parent_dir,corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_corpus_file = os.path.join(corpus_path_whole, \"dev_corpus.json\")\n",
    "with open(dev_corpus_file, \"w\") as f:\n",
    "    json.dump(ordered_transcripts_dev, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_file = os.path.join(corpus_path_whole, \"train_corpus.json\")\n",
    "with open(train_corpus_file, \"w\") as f:\n",
    "    json.dump(ordered_transcripts_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus_file = os.path.join(corpus_path_whole, \"test_corpus.json\")\n",
    "with open(test_corpus_file, \"w\") as f:\n",
    "    json.dump(ordered_transcripts_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_features = os.path.join(corpus_path_whole, \"train_audio_features.pickle\")\n",
    "with open(train_audio_features, \"wb\") as f:\n",
    "    pickle.dump(audio_feature_list_train, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mfcc_features = os.path.join(corpus_path_whole, \"train_mfcc_features.pickle\")\n",
    "with open(train_mfcc_features, \"wb\") as f:\n",
    "    pickle.dump(mfcc_list_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_features = os.path.join(corpus_path_whole, \"test_audio_features.pickle\")\n",
    "with open(test_audio_features, \"wb\") as f:\n",
    "    pickle.dump(audio_feature_list_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mfcc_features = os.path.join(corpus_path_whole, \"test_mfcc_features.pickle\")\n",
    "with open(test_mfcc_features, \"wb\") as f:\n",
    "    pickle.dump(mfcc_list_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_audio_features = os.path.join(corpus_path_whole, \"dev_audio_features.pickle\")\n",
    "with open(dev_audio_features, \"wb\") as f:\n",
    "    pickle.dump(audio_feature_list_dev, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mfcc_features = os.path.join(corpus_path_whole, \"dev_mfcc_features.pickle\")\n",
    "with open(dev_mfcc_features, \"wb\") as f:\n",
    "    pickle.dump(mfcc_list_dev, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
